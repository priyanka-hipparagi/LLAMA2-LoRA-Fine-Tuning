# LLAMA2-LoRA-Fine-Tuning
This project demonstrates the fine-tuning of the LLAMA 2 model using Parameter Efficient Transfer Learning techniques: LoRA (Low-Rank Adaptation) and QLoRA (Quantized LoRA). It showcases efficient adaptation of a large language model to a custom dataset while minimizing computational overhead.
